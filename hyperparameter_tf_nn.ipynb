{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bopeng-sue/Optimal-Biofluid-Matrices-for-Human-Exposome-Biomonitoring/blob/main/hyperparameter_tf_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AV8qKXwKt2aK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem import AllChem, MACCSkeys, Descriptors\n",
        "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    balanced_accuracy_score,\n",
        "    roc_auc_score,\n",
        "    classification_report,\n",
        "    roc_curve,\n",
        "    precision_recall_curve,\n",
        "    auc\n",
        ")\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "RDLogger.DisableLog('rdApp.*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_GAai_fxS-h",
        "outputId": "adcea101-8441-4b7a-a432-b396e619de23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUs available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(\"GPUs available:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPCCLLcoxbq5",
        "outputId": "30a38aff-b0c8-4d78-bf7f-bf98bcd164b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is configured for use.\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU is configured for use.\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"GPU configuration error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "E3xY0n1Zu7_W",
        "outputId": "ab71030b-4d39-4945-9719-fd8a824eb6b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Biomonitor Compound PubChem CID  Blood study numbers  \\\n",
              "0           0                               70                    0   \n",
              "1           1                               89                    0   \n",
              "\n",
              "   Urine study numbers  Tendency for the selection of blood samples  \\\n",
              "0                    2                                          0.0   \n",
              "1                    1                                          0.0   \n",
              "\n",
              "  Biospecimen CAS Number                        Name  \\\n",
              "0       Urine   816-66-0  4-Methyl-2-oxovaleric acid   \n",
              "1       Urine   484-78-6           Hydroxykynurenine   \n",
              "\n",
              "                                SMILES  hhlb(hours)  ...  JGI10       JGT  \\\n",
              "0                    CC(C)CC(=O)C(=O)O         0.61  ...    0.0  0.601944   \n",
              "1  C1=CC(=C(C(=C1)O)N)C(=O)CC(C(=O)O)N         0.43  ...    0.0  0.556317   \n",
              "\n",
              "      VE1_D     VE3_D       VR1_D      VR2_D  SRW5       AMW     WTPT-3  XLogP  \n",
              "0  0.046505 -2.761367   35.180772   3.908975   0.0  6.845421   7.158910  0.904  \n",
              "1  0.130944 -3.252780  192.246721  12.015420   0.0  8.002847  14.772289 -2.464  \n",
              "\n",
              "[2 rows x 680 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88e4f5f4-767f-4b27-8a85-0c01e5aecb0c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Biomonitor Compound PubChem CID</th>\n",
              "      <th>Blood study numbers</th>\n",
              "      <th>Urine study numbers</th>\n",
              "      <th>Tendency for the selection of blood samples</th>\n",
              "      <th>Biospecimen</th>\n",
              "      <th>CAS Number</th>\n",
              "      <th>Name</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>hhlb(hours)</th>\n",
              "      <th>...</th>\n",
              "      <th>JGI10</th>\n",
              "      <th>JGT</th>\n",
              "      <th>VE1_D</th>\n",
              "      <th>VE3_D</th>\n",
              "      <th>VR1_D</th>\n",
              "      <th>VR2_D</th>\n",
              "      <th>SRW5</th>\n",
              "      <th>AMW</th>\n",
              "      <th>WTPT-3</th>\n",
              "      <th>XLogP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Urine</td>\n",
              "      <td>816-66-0</td>\n",
              "      <td>4-Methyl-2-oxovaleric acid</td>\n",
              "      <td>CC(C)CC(=O)C(=O)O</td>\n",
              "      <td>0.61</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.601944</td>\n",
              "      <td>0.046505</td>\n",
              "      <td>-2.761367</td>\n",
              "      <td>35.180772</td>\n",
              "      <td>3.908975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.845421</td>\n",
              "      <td>7.158910</td>\n",
              "      <td>0.904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Urine</td>\n",
              "      <td>484-78-6</td>\n",
              "      <td>Hydroxykynurenine</td>\n",
              "      <td>C1=CC(=C(C(=C1)O)N)C(=O)CC(C(=O)O)N</td>\n",
              "      <td>0.43</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.556317</td>\n",
              "      <td>0.130944</td>\n",
              "      <td>-3.252780</td>\n",
              "      <td>192.246721</td>\n",
              "      <td>12.015420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.002847</td>\n",
              "      <td>14.772289</td>\n",
              "      <td>-2.464</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 680 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88e4f5f4-767f-4b27-8a85-0c01e5aecb0c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88e4f5f4-767f-4b27-8a85-0c01e5aecb0c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88e4f5f4-767f-4b27-8a85-0c01e5aecb0c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aaca4de4-b6c7-426b-849b-82be886ab89f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aaca4de4-b6c7-426b-849b-82be886ab89f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aaca4de4-b6c7-426b-849b-82be886ab89f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.read_excel('dataset_1211.xlsx')\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q_9Zsfs46Lt"
      },
      "source": [
        "# feature function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ney7ZEtK5nV8"
      },
      "outputs": [],
      "source": [
        "def padel_descriptor(df: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Extracts Padel descriptors from a given DataFrame starting from column index 16\n",
        "    to the end. It replaces NaN values with 0 and infinite values with 1e10.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        The input DataFrame containing feature columns.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        A NumPy array of transformed feature values.\n",
        "    \"\"\"\n",
        "    # Slice columns from index 16 to the end\n",
        "    X = df.iloc[:, 16:].values\n",
        "\n",
        "    # Replace NaNs with 0\n",
        "    X = np.nan_to_num(X, nan=0.0)\n",
        "\n",
        "    # Replace infinities with a large finite value\n",
        "    X[np.isinf(X)] = 1e10\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "f4cAvPvt6FDC"
      },
      "outputs": [],
      "source": [
        "def maccs_descriptor(smiles_list):\n",
        "    \"\"\"\n",
        "    Generates MACCS fingerprints for a list of SMILES strings and returns them as a DataFrame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    smiles_list : list of str\n",
        "        A list of SMILES strings for which MACCS keys will be generated.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        A DataFrame of MACCS bit values (0 or 1) with column names 'MACCS_1' through 'MACCS_167'.\n",
        "    \"\"\"\n",
        "    # Generate MACCS fingerprints and convert them to a list of bits\n",
        "    maccs_fingerprints = [\n",
        "        list(MACCSkeys.GenMACCSKeys(Chem.MolFromSmiles(smiles)).ToBitString())\n",
        "        for smiles in smiles_list\n",
        "    ]\n",
        "\n",
        "    # Convert the list of bits to a DataFrame\n",
        "    # MACCSkeys are 167 bits long, hence 167 columns\n",
        "    X = pd.DataFrame(maccs_fingerprints, columns=[f'MACCS_{i}' for i in range(1, 168)])\n",
        "\n",
        "    # Convert strings to integers (0 and 1)\n",
        "    X = X.astype(int)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9QflQAOr6Fh4"
      },
      "outputs": [],
      "source": [
        "def ecfp_descriptor(smiles_list, radius=2, n_bits=1024):\n",
        "    \"\"\"\n",
        "    Generates ECFP (Extended-Connectivity Fingerprints) for a list of SMILES strings\n",
        "    and returns them as a NumPy array.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    smiles_list : list of str\n",
        "        A list of SMILES strings for which ECFP fingerprints will be generated.\n",
        "    radius : int, optional (default=2)\n",
        "        The fingerprint radius to use. For ECFP4, radius=2 is standard.\n",
        "    n_bits : int, optional (default=1024)\n",
        "        Length of the bit vector.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        A 2D NumPy array where each row corresponds to the ECFP bit vector of the input SMILES.\n",
        "    \"\"\"\n",
        "    def calculate_ecfp(smiles, radius=radius, n_bits=n_bits):\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is not None:\n",
        "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=n_bits, useFeatures=False)\n",
        "            return np.array(fp)\n",
        "        else:\n",
        "            return np.zeros(n_bits, dtype=int)\n",
        "\n",
        "    # Apply ECFP calculation to the input list of SMILES\n",
        "    ecfp_fingerprints = np.array([calculate_ecfp(s) for s in smiles_list])\n",
        "    return ecfp_fingerprints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QfC8nXHv6Idk"
      },
      "outputs": [],
      "source": [
        "def fcfp_descriptor(smiles_list, radius=2, n_bits=1024):\n",
        "    \"\"\"\n",
        "    Generates FCFP (Feature-based Circular Fingerprints) for a list of SMILES strings\n",
        "    and returns them as a NumPy array.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    smiles_list : list of str\n",
        "        A list of SMILES strings for which FCFP fingerprints will be generated.\n",
        "    radius : int, optional (default=2)\n",
        "        The fingerprint radius to use.\n",
        "    n_bits : int, optional (default=1024)\n",
        "        Length of the bit vector.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        A 2D NumPy array where each row corresponds to the FCFP bit vector of the input SMILES.\n",
        "    \"\"\"\n",
        "    def calculate_fcfp(smiles, radius=radius, n_bits=n_bits):\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is not None:\n",
        "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=n_bits, useFeatures=True)\n",
        "            return np.array(fp)\n",
        "        else:\n",
        "            return np.zeros(n_bits, dtype=int)\n",
        "\n",
        "    # Apply FCFP calculation to the input list of SMILES\n",
        "    fcfp_fingerprints = np.array([calculate_fcfp(s) for s in smiles_list])\n",
        "    return fcfp_fingerprints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SWZQCXgq6DAx"
      },
      "outputs": [],
      "source": [
        "def rdkit_descriptors_to_X(df: pd.DataFrame, smiles_col='SMILES', correlation_threshold=0.95) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute RDKit molecular descriptors for each SMILES in the given DataFrame,\n",
        "    remove descriptors with zero variance and highly correlated descriptors,\n",
        "    and return the final feature matrix X.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        A DataFrame containing at least a 'SMILES' column.\n",
        "    smiles_col : str, optional\n",
        "        The name of the column containing SMILES strings.\n",
        "    correlation_threshold : float, optional\n",
        "        Threshold above which descriptors are considered highly correlated and removed.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        A 2D NumPy array containing the filtered RDKit descriptors.\n",
        "    \"\"\"\n",
        "    # Convert SMILES to RDKit Mol objects\n",
        "    mol_list = [Chem.MolFromSmiles(s) for s in df[smiles_col]]\n",
        "\n",
        "    # Define the descriptor names\n",
        "    descriptor_names = [desc_name[0] for desc_name in Descriptors._descList]\n",
        "\n",
        "    # Create a descriptor calculator\n",
        "    calculator = MoleculeDescriptors.MolecularDescriptorCalculator(descriptor_names)\n",
        "\n",
        "    # Calculate descriptors for each molecule, if mol is None use NaNs\n",
        "    descriptors_list = [\n",
        "        calculator.CalcDescriptors(mol) if mol is not None else [np.nan]*len(descriptor_names)\n",
        "        for mol in mol_list\n",
        "    ]\n",
        "\n",
        "    # Convert the list of descriptors to a DataFrame\n",
        "    descriptors_df = pd.DataFrame(descriptors_list, columns=descriptor_names)\n",
        "\n",
        "    # Replace NaNs with 0\n",
        "    descriptors_df = descriptors_df.fillna(0)\n",
        "\n",
        "    # Step 1: Remove descriptors with zero variance\n",
        "    variance = descriptors_df.var()\n",
        "    zero_variance_columns = variance[variance == 0].index\n",
        "    descriptors_df = descriptors_df.drop(columns=zero_variance_columns)\n",
        "\n",
        "    # Step 2: Remove descriptors with correlation exceeding the threshold\n",
        "    corr = descriptors_df.corr().abs()\n",
        "    to_drop = []\n",
        "\n",
        "    for i, col1 in enumerate(corr.columns):\n",
        "        for col2 in corr.columns[i+1:]:\n",
        "            if corr.loc[col1, col2] > correlation_threshold:\n",
        "                to_drop.append(col2)\n",
        "\n",
        "    # Remove duplicates if any\n",
        "    to_drop = list(set(to_drop))\n",
        "\n",
        "    # Drop the highly correlated descriptors\n",
        "    descriptors_df = descriptors_df.drop(columns=to_drop, errors='ignore')\n",
        "\n",
        "    # Convert the final descriptors DataFrame to a NumPy array\n",
        "    X = descriptors_df.values\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQyVCTZYiMiV"
      },
      "source": [
        "# Hyperparameter_NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FttGXgeEiOr-"
      },
      "source": [
        "Descriptor Processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pGNGmXK9iMuT"
      },
      "outputs": [],
      "source": [
        "def compute_descriptors(df: pd.DataFrame, descriptor_type: str, smiles_col: str='SMILES') -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Computes the specified molecular descriptor for the given DataFrame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        Input DataFrame containing at least the 'SMILES' column.\n",
        "    descriptor_type : str\n",
        "        Type of descriptor to compute. One of ['padel', 'maccs', 'ecfp', 'fcfp', 'rdkit'].\n",
        "    smiles_col : str, optional\n",
        "        Name of the column containing SMILES strings.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Feature matrix as a NumPy array.\n",
        "    \"\"\"\n",
        "    if descriptor_type.lower() == 'padel':\n",
        "        X = padel_descriptor(df)\n",
        "    elif descriptor_type.lower() == 'maccs':\n",
        "        X = maccs_descriptor(df[smiles_col].tolist()).values\n",
        "    elif descriptor_type.lower() == 'ecfp':\n",
        "        X = ecfp_descriptor(df[smiles_col].tolist())\n",
        "    elif descriptor_type.lower() == 'fcfp':\n",
        "        X = fcfp_descriptor(df[smiles_col].tolist())\n",
        "    elif descriptor_type.lower() == 'rdkit':\n",
        "        X = rdkit_descriptors_to_X(df, smiles_col=smiles_col, correlation_threshold=0.95)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid descriptor_method. Choose from 'padel', 'maccs', 'fcfp', 'ecfp', 'rdkit'.\")\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXTRwuPxiVVO"
      },
      "source": [
        "Machine Learning Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JOhS6HjovHFk"
      },
      "outputs": [],
      "source": [
        "def run_ml_pipeline(\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    descriptor_type: str,\n",
        "    model_output_path: str='models/',\n",
        "    max_evals: int=2000,\n",
        "    random_state: int=42\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Runs the machine learning pipeline for a given descriptor type using TensorFlow,\n",
        "    trains the best neural network model, evaluates it, and returns performance metrics.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : np.ndarray\n",
        "        Feature matrix.\n",
        "    y : np.ndarray\n",
        "        Target vector.\n",
        "    descriptor_type : str\n",
        "        Descriptor type being processed.\n",
        "    model_output_path : str, optional\n",
        "        Directory path to save the models. Defaults to 'models/'.\n",
        "    max_evals : int, optional\n",
        "        Maximum number of evaluations for hyperparameter optimization. Defaults to 50.\n",
        "    random_state : int, optional\n",
        "        Random state for reproducibility. Defaults to 42.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        A dictionary containing performance metrics.\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    Path(model_output_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 1. Data Splitting\n",
        "    # ---------------------------\n",
        "\n",
        "    # Initialize the first split: train + temp (validation + test)\n",
        "    sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=random_state)\n",
        "    for train_index, temp_index in sss1.split(X, y):\n",
        "        X_train, X_temp = X[train_index], X[temp_index]\n",
        "        y_train, y_temp = y[train_index], y[temp_index]\n",
        "\n",
        "    # Initialize the second split: validation + test from temp\n",
        "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=2/3, random_state=random_state)  # 1/3 validation, 2/3 test\n",
        "    for val_index, test_index in sss2.split(X_temp, y_temp):\n",
        "        X_val, X_test = X_temp[val_index], X_temp[test_index]\n",
        "        y_val, y_test = y_temp[val_index], y_temp[test_index]\n",
        "\n",
        "    print(f\"Dataset sizes for {descriptor_type}:\")\n",
        "    print(f\"Training set: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "    print(f\"Validation set: X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "    print(f\"Test set: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # 2. Apply SMOTE\n",
        "    # ---------------------------\n",
        "\n",
        "    smote = SMOTE(random_state=random_state)\n",
        "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(f\"After SMOTE, training set sizes for {descriptor_type}:\")\n",
        "    print(f\"X_train_res: {X_train_res.shape}, y_train_res: {y_train_res.shape}\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # 3. Hyperparameter Optimization\n",
        "    # ---------------------------\n",
        "\n",
        "    def objective(space):\n",
        "        model = Sequential([\n",
        "            Dense(int(space['units1']), activation='relu', input_shape=(X_train_res.shape[1],)),\n",
        "            Dropout(space['dropout1']),\n",
        "            Dense(int(space['units2']), activation='relu'),\n",
        "            Dropout(space['dropout2']),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=space['learning_rate']),\n",
        "                      loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train_res, y_train_res,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=50,\n",
        "            batch_size=int(space['batch_size']),\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        val_loss = min(history.history['val_loss'])\n",
        "        return {'loss': val_loss, 'status': STATUS_OK, 'model': model}\n",
        "\n",
        "    # Define the search space\n",
        "    space = {\n",
        "        'units1': hp.quniform('units1', 64, 256, 16),\n",
        "        'dropout1': hp.uniform('dropout1', 0.1, 0.5),\n",
        "        'units2': hp.quniform('units2', 32, 128, 16),\n",
        "        'dropout2': hp.uniform('dropout2', 0.1, 0.5),\n",
        "        'batch_size': hp.quniform('batch_size', 16, 64, 8),\n",
        "        'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01))\n",
        "    }\n",
        "\n",
        "    trials = Trials()\n",
        "    best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=max_evals, trials=trials, rstate=np.random.default_rng(random_state))\n",
        "\n",
        "    # Retrieve the best model\n",
        "    best_model = None\n",
        "    for trial in trials.trials:\n",
        "        if trial['result']['status'] == STATUS_OK:\n",
        "            best_model = trial['result']['model']\n",
        "            break\n",
        "\n",
        "    # ---------------------------\n",
        "    # 4. Evaluation on Test Set\n",
        "    # ---------------------------\n",
        "\n",
        "    y_pred_probs = best_model.predict(X_test).flatten()\n",
        "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision = precision_score(y_test, y_pred, average='binary')\n",
        "    recall = recall_score(y_test, y_pred, average='binary')\n",
        "    f1 = f1_score(y_test, y_pred, average='binary')\n",
        "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "    auc_score = roc_auc_score(y_test, y_pred_probs)\n",
        "\n",
        "    print(f\"\\nNeural Network Model Performance on Test Set ({descriptor_type}):\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "    print(f\"AUC-ROC:   {auc_score:.4f}\")\n",
        "\n",
        "    # Detailed classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # ---------------------------\n",
        "    # 5. Save the TensorFlow Model\n",
        "    # ---------------------------\n",
        "\n",
        "    model_path = f'{model_output_path}/best_nn_model_{descriptor_type}.h5'\n",
        "    best_model.save(model_path)\n",
        "    print(f\"Neural Network model saved to {model_path}\\n\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # 6. Compile Performance Metrics\n",
        "    # ---------------------------\n",
        "\n",
        "    results_nn = {\n",
        "        'Model Type': 'Neural Network',\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'Balanced Accuracy': balanced_acc,\n",
        "        'AUC-ROC': auc_score,\n",
        "        'Model Path': model_path\n",
        "    }\n",
        "\n",
        "    return results_nn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC108M-yjFCA",
        "outputId": "0ce4631a-5ea1-4767-dea2-4fc88355a9a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model screening for descriptor method: rdkit\n",
            "Dataset sizes for rdkit:\n",
            "Training set: X_train: (321, 149), y_train: (321,)\n",
            "Validation set: X_val: (71, 149), y_val: (71,)\n",
            "Test set: X_test: (144, 149), y_test: (144,)\n",
            "After SMOTE, training set sizes for rdkit:\n",
            "X_train_res: (396, 149), y_train_res: (396,)\n",
            "100%|██████████| 1000/1000 [1:41:39<00:00,  6.10s/trial, best loss: 0.5288572311401367]\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 323ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Neural Network Model Performance on Test Set (rdkit):\n",
            "Precision: 0.7642\n",
            "Recall:    0.9205\n",
            "F1-Score:  0.8351\n",
            "Balanced Accuracy: 0.7370\n",
            "AUC-ROC:   0.7885\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.55      0.66        56\n",
            "           1       0.76      0.92      0.84        88\n",
            "\n",
            "    accuracy                           0.78       144\n",
            "   macro avg       0.79      0.74      0.75       144\n",
            "weighted avg       0.78      0.78      0.77       144\n",
            "\n",
            "Neural Network model saved to models//best_nn_model_rdkit.h5\n",
            "\n",
            "All results saved to models/all_descriptor_results.csv\n",
            "\n",
            "Summary of All Descriptor Methods:\n",
            "           Model Type Precision    Recall  F1-Score Balanced Accuracy  \\\n",
            "rdkit  Neural Network  0.764151  0.920455  0.835052          0.737013   \n",
            "\n",
            "        AUC-ROC                      Model Path  \n",
            "rdkit  0.788454  models//best_nn_model_rdkit.h5  \n"
          ]
        }
      ],
      "source": [
        "def run_descriptor_model_screening(\n",
        "    df: pd.DataFrame,\n",
        "    target_col: str,\n",
        "    smiles_col: str='SMILES',\n",
        "    descriptor_method: str='padel',\n",
        "    model_output_path: str='models/',\n",
        "    max_evals: int=1000,\n",
        "    random_state: int=42\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Runs the descriptor model screening for a given descriptor method.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        Input DataFrame containing the data.\n",
        "    target_col : str\n",
        "        The name of the target column.\n",
        "    smiles_col : str, optional\n",
        "        The name of the SMILES column. Defaults to 'SMILES'.\n",
        "    descriptor_method : str, optional\n",
        "        The descriptor method to use. One of ['padel', 'maccs', 'fcfp', 'ecfp', 'rdkit'].\n",
        "    model_output_path : str, optional\n",
        "        Directory path to save the models and plots. Defaults to 'models/'.\n",
        "    max_evals : int, optional\n",
        "        Maximum number of evaluations for hyperparameter optimization. Defaults to 50.\n",
        "    random_state : int, optional\n",
        "        Random state for reproducibility. Defaults to 42.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        A dictionary containing performance metrics and paths.\n",
        "    \"\"\"\n",
        "    print(f\"Starting model screening for descriptor method: {descriptor_method}\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # 1. Extract and Binarize Target\n",
        "    # ---------------------------\n",
        "    y = (df[target_col] > 0.5).astype(int).values\n",
        "\n",
        "    # ---------------------------\n",
        "    # 2. Compute Features X\n",
        "    # ---------------------------\n",
        "    try:\n",
        "        X = compute_descriptors(df, descriptor_type=descriptor_method, smiles_col=smiles_col)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error computing descriptors: {e}\")\n",
        "        return {}\n",
        "\n",
        "    # ---------------------------\n",
        "    # 3. Run Machine Learning Pipeline\n",
        "    # ---------------------------\n",
        "    results = run_ml_pipeline(\n",
        "        X=X,\n",
        "        y=y,\n",
        "        descriptor_type=descriptor_method,\n",
        "        model_output_path=model_output_path,\n",
        "        max_evals=max_evals,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to execute the machine learning pipeline for each descriptor type.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define descriptor methods you want to test\n",
        "    descriptor_methods = [\n",
        "        # 'padel', 'maccs','fcfp','ecfp',\n",
        "                            'rdkit']\n",
        "\n",
        "    # Dictionary to store the results for each descriptor method\n",
        "    all_results = {}\n",
        "\n",
        "\n",
        "    for method in descriptor_methods:\n",
        "        results = run_descriptor_model_screening(\n",
        "            df=df,\n",
        "            target_col='Tendency for the selection of blood samples',\n",
        "            smiles_col='SMILES',\n",
        "            descriptor_method=method,\n",
        "            model_output_path='models/',\n",
        "            max_evals=1000,\n",
        "            random_state=42\n",
        "        )\n",
        "        all_results[method] = results\n",
        "\n",
        "    # ---------------------------\n",
        "    # 4. Save All Results to a CSV\n",
        "    # ---------------------------\n",
        "\n",
        "    # Convert results dictionary to a DataFrame for saving\n",
        "    results_df = pd.DataFrame(all_results).T  # Transpose for better readability\n",
        "    results_csv_path = 'models/all_descriptor_results.csv'\n",
        "    results_df.to_csv(results_csv_path)\n",
        "    print(f\"All results saved to {results_csv_path}\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # 5. Display Summary\n",
        "    # ---------------------------\n",
        "\n",
        "    print(\"\\nSummary of All Descriptor Methods:\")\n",
        "    print(results_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNwo8ZKv765WKWomIuJU+Nq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}